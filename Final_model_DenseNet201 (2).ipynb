{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_model_DenseNet201.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aHsZEhMEL3rx",
        "colab": {}
      },
      "source": [
        "# Native Python Library\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import math\n",
        "import scipy.misc\n",
        "import tensorflow as tf\n",
        "import imageio\n",
        "from scipy import misc\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.densenet import DenseNet201\n",
        "from tensorflow.keras.applications.nasnet import NASNetLarge\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation,Dense, Dropout, Flatten, BatchNormalization, Input,GlobalAveragePooling2D\n",
        "import ssl\n",
        "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and\n",
        "    getattr(ssl, '_create_unverified_context', None)): \n",
        "    ssl._create_default_https_context = ssl._create_unverified_context   \n",
        "config = tf.ConfigProto(allow_soft_placement = True)\n",
        "sess = tf.Session(config=config) \n",
        "tf.keras.backend.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ho7SIuVuL3r1",
        "colab": {}
      },
      "source": [
        "#configuration \n",
        "IMAGE_H = 299\n",
        "IMAGE_W = 299\n",
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DK2UnFQpL3r3",
        "colab": {}
      },
      "source": [
        "train_data_file_path = \"/root/deeplearning/train2014\"\n",
        "label_data_file_path = \"/root/deeplearning\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "claAMAXS6ePs",
        "colab_type": "text"
      },
      "source": [
        "# Load the train data and resize them to 299*299"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_jZf_JPmL3r6",
        "outputId": "4a15bf4a-28ed-40f0-bd24-f5a7aac8334c",
        "colab": {}
      },
      "source": [
        "# load all the image file into numpy array may take 2minutes according to image size (148sec for size 224*224)\n",
        "import time\n",
        "start = time. time()\n",
        "\n",
        "os.chdir(train_data_file_path)\n",
        "train_file_list = os.listdir(train_data_file_path)\n",
        "# load the train data\n",
        "train_data = np.array([np.array(cv2.resize( cv2.imread(filename), (IMAGE_H,IMAGE_W))) for filename in train_file_list])\n",
        "train_data_file_name = pd.DataFrame(np.array([filename for filename in train_file_list]))\n",
        "train_data_file_name.columns = ['filename']\n",
        "\n",
        "end = time. time()\n",
        "print(end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "230.35574626922607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-r5FVo_6ePx",
        "colab_type": "text"
      },
      "source": [
        "# Load the test data and resize them to 299*299"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAM362an6ePy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_data_file_path = \"/root/deeplearning/val2014\"\n",
        "os.chdir(valid_data_file_path)\n",
        "valid_file_list = os.listdir(valid_data_file_path)\n",
        "valid_data =  np.array([np.array(cv2.resize( cv2.imread(filename), (IMAGE_H,IMAGE_W))) for filename in valid_file_list])\n",
        "valid_data_file_name = pd.DataFrame(np.array([filename for filename in os.listdir(valid_data_file_path)]))\n",
        "valid_data_file_name.columns = ['filename']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytw-WSR_6eP1",
        "colab_type": "text"
      },
      "source": [
        "# Load the train label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5GcZzmnrL3r9",
        "colab": {}
      },
      "source": [
        "# Read all train label from local devices\n",
        "os.chdir(label_data_file_path)\n",
        "train_label_file =  pd.read_csv(label_data_file_path + '/train.txt', sep='\\t', names=['filename','label'])\n",
        "train_label = pd.merge(train_data_file_name, train_label_file,on='filename')[['label']]\n",
        "train_label = np.array(train_label).T[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y357Ge_qL3r_",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "#process data using one hot \n",
        "duplicate_train_label = train_label\n",
        "label_list = np.ndarray.tolist(duplicate_train_label)\n",
        "\n",
        "result_set = []\n",
        "for item in label_list:\n",
        "    if item.find(\",\")!=-1:\n",
        "        array = item.split(\",\")\n",
        "        item = set(array)\n",
        "        result_set.append(item)\n",
        "    else:     \n",
        "        item = {item}\n",
        "        result_set.append(item)\n",
        "        \n",
        "real_label = np.zeros((len(result_set),20))\n",
        "for i in range(real_label.shape[0]):\n",
        "    for d in result_set[i]:\n",
        "        real_label[i][int(d)] = 1\n",
        "\n",
        "#Split data using train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(train_data,real_label,test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYkzo_Hg6eP7",
        "colab_type": "text"
      },
      "source": [
        "# DenseNet201 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uYG2FfsDL3sE",
        "colab": {}
      },
      "source": [
        "# use pretrained model resnet50 and add several fully connected layer\n",
        "input_shape = (IMAGE_H, IMAGE_W, 3)\n",
        "inputs = Input(shape=input_shape)\n",
        "pretrained_model = DenseNet201(include_top=False,\n",
        "                      weights='imagenet',\n",
        "                      input_shape=input_shape\n",
        "                      )\n",
        "x = pretrained_model(inputs)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "\n",
        "outputs = Dense(20, activation='sigmoid')(x)\n",
        "model = Model(inputs, outputs)\n",
        "model.layers[1].trainable = False\n",
        "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFcl5aCX6eP-",
        "colab_type": "text"
      },
      "source": [
        "# Train 80% data, test 20%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qh9BAYPFL3sH",
        "outputId": "14f5bdeb-7b71-4e8c-8bf8-ac8c54afb5ff",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# save the accuracy and loss for each epoch\n",
        "val_acc = []\n",
        "val_loss = []\n",
        "# train with 8 epochs\n",
        "for j in range(0,8):\n",
        "    history = model.fit(X_train, Y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=1,\n",
        "            verbose=1,\n",
        "            validation_data=(X_test, Y_test))\n",
        "    y_predict = model.predict(X_test)\n",
        "    top_1 = np.array([np.argmax(i) for i in y_predict])\n",
        "    count = 0\n",
        "    for i in range(len(top_1)):\n",
        "        if Y_test[i,top_1[i]] == 1:\n",
        "            count += 1\n",
        "    print(count/len(top_1))\n",
        "    val_acc.append(count/len(top_1))\n",
        "    val_loss.append(history.history['val_loss'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25540 samples, validate on 6385 samples\n",
            "25540/25540 [==============================] - 206s 8ms/sample - loss: 0.1433 - acc: 0.9487 - val_loss: 0.1152 - val_acc: 0.9568\n",
            "0.6867658574784652\n",
            "Train on 25540 samples, validate on 6385 samples\n",
            "25540/25540 [==============================] - 193s 8ms/sample - loss: 0.1082 - acc: 0.9596 - val_loss: 0.1078 - val_acc: 0.9600\n",
            "0.7158966327329679\n",
            "Train on 25540 samples, validate on 6385 samples\n",
            "25540/25540 [==============================] - 193s 8ms/sample - loss: 0.1012 - acc: 0.9620 - val_loss: 0.1065 - val_acc: 0.9602\n",
            "0.7201252936570086\n",
            "Train on 25540 samples, validate on 6385 samples\n",
            "25540/25540 [==============================] - 193s 8ms/sample - loss: 0.0965 - acc: 0.9636 - val_loss: 0.1054 - val_acc: 0.9607\n",
            "0.7194988253719655\n",
            "Train on 25540 samples, validate on 6385 samples\n",
            "25540/25540 [==============================] - 193s 8ms/sample - loss: 0.0925 - acc: 0.9648 - val_loss: 0.1065 - val_acc: 0.9608\n",
            "0.7215348472983555\n",
            "Train on 25540 samples, validate on 6385 samples\n",
            "25540/25540 [==============================] - 193s 8ms/sample - loss: 0.0902 - acc: 0.9657 - val_loss: 0.1072 - val_acc: 0.9603\n",
            "0.7213782302270948\n",
            "Train on 25540 samples, validate on 6385 samples\n",
            "25540/25540 [==============================] - 193s 8ms/sample - loss: 0.0870 - acc: 0.9668 - val_loss: 0.1079 - val_acc: 0.9606\n",
            "0.727956147220047\n",
            "Train on 25540 samples, validate on 6385 samples\n",
            "25540/25540 [==============================] - 193s 8ms/sample - loss: 0.0833 - acc: 0.9679 - val_loss: 0.1050 - val_acc: 0.9615\n",
            "0.7340642129992169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0Luq-PC6eQF",
        "colab_type": "text"
      },
      "source": [
        "# Train the entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnPpGHg26eQI",
        "colab_type": "code",
        "outputId": "ac26e68a-7c58-4a3e-9fee-9ce3810367c5",
        "colab": {}
      },
      "source": [
        "\n",
        "# train with 8 epochs by entire train set\n",
        "for j in range(0,8):\n",
        "    history = model.fit(train_data, real_label,\n",
        "            batch_size=batch_size,\n",
        "            epochs=1,\n",
        "            verbose=1,\n",
        "            validation_data=(X_test, Y_test))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 31925 samples, validate on 6385 samples\n",
            "31925/31925 [==============================] - 245s 8ms/sample - loss: 0.1381 - acc: 0.9503 - val_loss: 0.1085 - val_acc: 0.9597\n",
            "Train on 31925 samples, validate on 6385 samples\n",
            "31925/31925 [==============================] - 232s 7ms/sample - loss: 0.1069 - acc: 0.9602 - val_loss: 0.1020 - val_acc: 0.9615\n",
            "Train on 31925 samples, validate on 6385 samples\n",
            "31925/31925 [==============================] - 232s 7ms/sample - loss: 0.1009 - acc: 0.9621 - val_loss: 0.0945 - val_acc: 0.9641\n",
            "Train on 31925 samples, validate on 6385 samples\n",
            "31925/31925 [==============================] - 232s 7ms/sample - loss: 0.0963 - acc: 0.9637 - val_loss: 0.0953 - val_acc: 0.9641\n",
            "Train on 31925 samples, validate on 6385 samples\n",
            "31925/31925 [==============================] - 232s 7ms/sample - loss: 0.0936 - acc: 0.9645 - val_loss: 0.0890 - val_acc: 0.9660\n",
            "Train on 31925 samples, validate on 6385 samples\n",
            "31925/31925 [==============================] - 232s 7ms/sample - loss: 0.0905 - acc: 0.9654 - val_loss: 0.0880 - val_acc: 0.9664\n",
            "Train on 31925 samples, validate on 6385 samples\n",
            "31925/31925 [==============================] - 232s 7ms/sample - loss: 0.0870 - acc: 0.9669 - val_loss: 0.0805 - val_acc: 0.9695\n",
            "Train on 31925 samples, validate on 6385 samples\n",
            "31925/31925 [==============================] - 232s 7ms/sample - loss: 0.0835 - acc: 0.9681 - val_loss: 0.0787 - val_acc: 0.9690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OXqGjXr6eQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('final_model_densenet201.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwgGZ4tn6eQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_predict = model.predict(valid_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn-rpyp26eQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "file = open('final_2.txt','w')\n",
        "for i in range(0, valid_data.shape[0]):\n",
        "    file.write(valid_data_file_name['filename'][i]+\"\\t\")\n",
        "    file.write(str(np.argmax(x_predict[i])) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOyLGB2a6eQY",
        "colab_type": "text"
      },
      "source": [
        "# Plot the accuracy and loss graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms4WMmzC6eQY",
        "colab_type": "code",
        "outputId": "fae42b08-de79-4bdd-816a-d2d2b4df13d0",
        "colab": {}
      },
      "source": [
        "plt.plot(val_acc)\n",
        "plt.plot(val_loss)\n",
        "plt.title('model accuracy vs loss')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['accuracy', 'val_loss'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ggC2Yax6eQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}